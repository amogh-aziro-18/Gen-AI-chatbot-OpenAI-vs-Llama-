# ğŸ¤– Q&A Multi-Model Chatbot using OpenRouter

## ğŸ§  Overview
**Q&A Multi-Model Chatbot** is an advanced **Streamlit-based application** designed to compare responses from **multiple Large Language Models (LLMs)** via the **OpenRouter API**.  
It supports **contextual memory**, **semantic search (FAISS-like)**, and **side-by-side model comparison**, making it ideal for analyzing response quality, accuracy, and reasoning across AI models.

---

## ğŸš€ Key Features

- ğŸ”€ **Dual Modes**
  - **Single Model Chat** â€“ Chat with one selected LLM interactively.  
  - **Comparison Mode** â€“ View and compare responses from two models simultaneously.

- ğŸ§© **Multi-Model Support**
  - **GPT-4o-mini (OpenAI)**
  - **GPT-4o (OpenAI)**
  - **LLaMA-3-8B Instruct (Meta)**
  - **LLaMA-3-13B Instruct (Meta)**

- ğŸ§  **Contextual Memory**
  - Stores all user queries and responses.
  - Uses **SentenceTransformer embeddings** (`all-MiniLM-L6-v2`) for semantic similarity.
  - Retrieves relevant past contexts using **cosine similarity**, functioning like a **FAISS-style vector store**.

- ğŸ’¬ **Modern Chat UI**
  - Built with **Streamlit**.
  - Model selector, mode toggle, and clean side-by-side layout.
  - Persistent memory and contextual display.
  - Bottom input box for natural chat flow.

- ğŸ”’ **Secure API Handling**
  - `.env` file used to store **OpenRouter API keys** safely.

---

## ğŸ› ï¸ Tech Stack

| Component | Technology Used |
|------------|----------------|
| **UI Framework** | Streamlit |
| **Backend Language** | Python |
| **API Gateway** | OpenRouter |
| **Embeddings Model** | `all-MiniLM-L6-v2` (SentenceTransformers) |
| **Vector Search** | Cosine Similarity (FAISS-like memory) |
| **Env Handling** | python-dotenv |
| **HTTP Requests** | requests |
| **LLMs Supported** | OpenAI GPT-4o, GPT-4o-mini, LLaMA-3 8B, LLaMA-3 13B |

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/yourusername/qa-multimodel-chatbot.git
cd qa-multimodel-chatbot
```

### 2ï¸âƒ£ Create and Activate a Virtual Environment
```bash
python -m venv venv
source venv/bin/activate       # For macOS/Linux
venv\Scripts\activate          # For Windows
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure Environment Variables
Create a `.env` file in the project root directory:
```
OPENROUTER_API_KEY=your_openrouter_api_key_here
```

You can get your API key from [https://openrouter.ai](https://openrouter.ai).

### 5ï¸âƒ£ Run the Application
```bash
streamlit run app.py
```

The app will open in your browser at [http://localhost:8501](http://localhost:8501).

---

## ğŸ“ Project Structure
```
ğŸ“¦ Q&A-MultiModel-Chatbot
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config.py
â”œâ”€â”€ utils/
â”œâ”€â”€ models/
â”œâ”€â”€ .env
â”œâ”€â”€ screenshots/
â”‚   â”œâ”€â”€ openai_models/
â”‚   â”œâ”€â”€ llama_models/
â”‚   â””â”€â”€ comparison/
â””â”€â”€ README.md
```

---

## ğŸ§® How Contextual Memory Works
1. User queries are converted to embeddings using **SentenceTransformer** (`all-MiniLM-L6-v2`).  
2. These vectors are stored in memory along with corresponding responses.  
3. On each new query, cosine similarity identifies the most relevant past entries.  
4. Retrieved contexts are included in the next model prompt for improved coherence and accuracy.  

> This architecture mimics **FAISS (Facebook AI Similarity Search)** but is implemented in-memory for simplicity and portability.

---

## ğŸ§  Model Behavior Customization

### ğŸ§© GPT-4o / GPT-4o-mini
- Provides structured, well-organized answers.
- Uses markdown formatting and factual style.

### ğŸ¦™ LLaMA-3 (8B / 13B)
- Concise, logic-driven responses.
- Clearly states uncertainty when unsure.

---

## ğŸ¨ User Interface Highlights
- Two-column layout for model comparison.
- Prompt box positioned at the bottom.
- Responsive, clean, and minimal dark UI.

---

## ğŸ“¸ Screenshots

All screenshots are stored in the **`/screenshots/`** folder.

| Folder | Description |
|---------|-------------|
| `/screenshots/openai_models/` | GPT-4o and GPT-4o-mini outputs |
| `/screenshots/llama_models/` | LLaMA-3 model outputs |
| `/screenshots/comparison/` | Side-by-side comparisons |

---

## ğŸ§¾ Example Usage

**Prompt:**  
> â€œWhat is the Model Context Protocol (MCP)?â€

**ğŸ§  GPT-4o-mini (OpenAI):**
- Structured, academic-style explanation with headers.

**ğŸ¦™ LLaMA-3-8B:**
- Concise bullet-point summary with uncertainty notes.

---

## ğŸ”’ Environment Variables

| Variable | Description |
|-----------|-------------|
| `OPENROUTER_API_KEY` | API key from OpenRouter |

---

## ğŸ“¦ Dependencies

```
streamlit
requests
sentence-transformers
scikit-learn
python-dotenv
numpy
```

---

## ğŸ‘¨â€ğŸ’» Author

**Amogh**  
Built with â¤ï¸ using Streamlit, OpenRouter, and SentenceTransformers.

---

## ğŸªª License
Licensed under the **MIT License**.

---
